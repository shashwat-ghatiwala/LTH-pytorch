{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505a3d1a",
   "metadata": {
    "id": "EIFB_Wh8Elkn"
   },
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befccb37",
   "metadata": {
    "id": "LOs_BMQBEYba"
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b3ae6",
   "metadata": {
    "id": "aXR6T7h7Et84"
   },
   "source": [
    "### Install cudf library\n",
    "\n",
    "Below is the method to install cudf on a colab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897a004",
   "metadata": {
    "id": "RxcDUQetEw0m"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "# !python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d633ba",
   "metadata": {
    "id": "S_wYuYUAFEmc"
   },
   "source": [
    "Check if cudf import works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58e29b",
   "metadata": {
    "id": "Md6w5JXWGmaV"
   },
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719f033e",
   "metadata": {
    "id": "cvx7lGZIGpM9"
   },
   "source": [
    " **Ensure datamodules.py is present in the local directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b92036",
   "metadata": {
    "id": "lyrG4rZHFGPS"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os, json\n",
    "import gc\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.nn.utils.prune as prune\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from merlin.dataloader.torch import Loader\n",
    "import torch.nn.init as init\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Custom Libraries\n",
    "from datamodules import merlin_dataset_factory, set_default_kwargs_dataset\n",
    "\n",
    "def get_latest_run(folder_path):\n",
    "\n",
    "    files = os.listdir(folder_path)\n",
    "    model_iters = [int(re.search(r'model_(\\d+)', file).group(1)) for file in files if re.match(r'model_(\\d+)', file)]\n",
    "\n",
    "    if model_iters:\n",
    "        latest_iter = max(model_iters)\n",
    "        print(f\"The latest model is: model_{latest_iter}\")\n",
    "        return os.path.join(folder_path, f\"model_{latest_iter}\"), latest_iter\n",
    "    else:\n",
    "        print(\"No model files found in the folder.\")\n",
    "        return None, None\n",
    "\n",
    "def get_latest_valacc(folder_path, ds='val'):\n",
    "    assert ds in ['val', 'test']\n",
    "    files = os.listdir(folder_path)\n",
    "    model_iters = [int(re.search(fr'{ds}_acc_(\\d+).json', file).group(1)) for file in files if re.match(fr'{ds}_acc_(\\d+).json', file)]\n",
    "\n",
    "    if model_iters:\n",
    "        latest_iter = max(model_iters)\n",
    "        fname = os.path.join(folder_path, fr'{ds}_acc_{latest_iter}.json')\n",
    "        with open(fname, \"r\") as f:\n",
    "            d = json.load(f)\n",
    "        return d['validation_accuracy'] if ds == 'val' else d['test_accuracy']\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def checkdir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# def remove_masks(model):\n",
    "#     for name, module in model.net.named_modules():\n",
    "#         if isinstance(module, nn.Linear):\n",
    "#             m1 = module\n",
    "#             m1 = prune.custom_from_mask(m1, name='weight', mask=model.mask[name].to(model.device))\n",
    "#             prune.remove(m1, 'weight')\n",
    "\n",
    "def save_files(iter, model):\n",
    "    save_path = os.path.join(model.get_path(), \"model_\"+str(iter))\n",
    "    print(save_path)\n",
    "    model.save_model(save_path)\n",
    "\n",
    "def save_val_acc(iter_arr, acc_arr, save_dir, ds='val'):\n",
    "    assert ds in ['val', 'test']\n",
    "    if ds == 'val':\n",
    "        d = {'pruned_iters':iter_arr, 'validation_accuracy':acc_arr}\n",
    "    else:\n",
    "        d = {'pruned_iters':iter_arr, 'test_accuracy':acc_arr}\n",
    "    fname = os.path.join(save_dir, f'{ds}_acc_{len(iter_arr)-1}.json')\n",
    "    print(fname)\n",
    "    with open(fname, \"w\") as f:\n",
    "        json.dump(d, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567623a",
   "metadata": {
    "id": "p4ISIxbZFHc8"
   },
   "source": [
    "### Setup - Path for Dataset and Model masks\n",
    "\n",
    "\n",
    "\n",
    "*   Add path to dataset\n",
    "*   Add path to where the pruned models and plots will be saved\n",
    "\n",
    "(I've provided a sample path for both as an example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c61bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.expanduser(\"~/data/sctab/merlin_cxg_2023_05_15_sf-log1p_minimal/\")\n",
    "save_path = os.path.expanduser(\"~/io/tmp_sparsity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468aac71",
   "metadata": {
    "id": "VHu9O-J3FPQt"
   },
   "outputs": [],
   "source": [
    "# manually create data loaders for train and validation set\n",
    "train_dataset = merlin_dataset_factory(\n",
    "    join(DATA_PATH, 'train'),\n",
    "    columns=['cell_type', 'tissue'],\n",
    "    dataset_kwargs=set_default_kwargs_dataset(training=True)\n",
    ")\n",
    "\n",
    "val_dataset = merlin_dataset_factory(\n",
    "    join(DATA_PATH, 'val'),\n",
    "    columns=['cell_type', 'tissue'],\n",
    "    dataset_kwargs=set_default_kwargs_dataset(training=False)\n",
    ")\n",
    "\n",
    "test_dataset = merlin_dataset_factory(\n",
    "    join(DATA_PATH, 'test'),\n",
    "    columns=['cell_type', 'tissue'],\n",
    "    dataset_kwargs=set_default_kwargs_dataset(training=False)\n",
    ")\n",
    "\n",
    "train_loader = Loader(train_dataset, batch_size=2048, shuffle=True)\n",
    "val_loader = Loader(val_dataset, batch_size=2048, shuffle=False)\n",
    "test_loader = Loader(test_dataset, batch_size=2048, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890e24f",
   "metadata": {
    "id": "8378PGgoF2pn"
   },
   "source": [
    "Loading model - Original model has 8 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60099334",
   "metadata": {
    "id": "fRFWlOBeF2RX"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        hidden_size: int = 128,\n",
    "        n_hidden: int = 8,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert n_hidden >= 1\n",
    "\n",
    "        modules = [\n",
    "            nn.Linear(input_dim, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        ]\n",
    "        for _ in range(1, n_hidden):\n",
    "            modules += [\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.SiLU(),\n",
    "                nn.Dropout(p=dropout)\n",
    "            ]\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.linear = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(self.encoder(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class PruningWrapper():\n",
    "    def __init__(self, net, device, dir):\n",
    "        self.net = net.to(device)\n",
    "        self.device = device\n",
    "\n",
    "        self.net_init_state = copy.deepcopy(self.net.state_dict())\n",
    "        self.mask = dict()\n",
    "        for name, module in self.net.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                self.mask[name] = torch.ones(module.weight.shape)\n",
    "\n",
    "        self.model_path = dir\n",
    "\n",
    "    def load_init_weights(self):\n",
    "        self.net.load_state_dict(state_dict=self.net_init_state)\n",
    "\n",
    "    def apply_mask_before_train(self):\n",
    "        for name, module in self.net.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module = prune.custom_from_mask(module, 'weight', self.mask[name].to(self.device))\n",
    "\n",
    "    def update_mask_after_train(self, p):\n",
    "        with torch.no_grad():\n",
    "            for name, module in self.net.named_modules():\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    prune.remove(module, 'weight')\n",
    "                    pruner = prune.L1Unstructured(amount=p)\n",
    "                    self.mask[name] = pruner.compute_mask(module.weight.data, torch.ones_like(module.weight.data))\n",
    "\n",
    "    def print_model_info(self):\n",
    "        mask_0, mask_1 = 0, 0\n",
    "        for _, mask in self.mask.items():\n",
    "            mask_0 += torch.sum(1 - mask).item()\n",
    "            mask_1 += torch.sum(mask).item()\n",
    "\n",
    "        print(f\"{(mask_0)/(mask_0 + mask_1)}% of parameters are masked.\")\n",
    "\n",
    "    def get_path(self):\n",
    "        return self.model_path\n",
    "\n",
    "    def pruned_proportion(self):\n",
    "        temp = 0\n",
    "        total = 0\n",
    "\n",
    "        for name, module in self.net.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                temp += module.weight_mask.sum().detach().item()\n",
    "                total += torch.ones(module.weight.shape).sum().item()\n",
    "            # break;\n",
    "        return round(1 - (temp / total), 3)\n",
    "\n",
    "    # def reinit_net(self, model_pruned):\n",
    "    #     for name, module in self.net.named_modules():\n",
    "    #         if isinstance(module, nn.Linear):\n",
    "    #             m1 = module\n",
    "    #             prune.remove(m1, 'weight')\n",
    "\n",
    "    def save_model(self, path):\n",
    "        d = {\n",
    "                'model_state_dict': self.net.state_dict(),\n",
    "                'init_state_dict': self.net_init_state,\n",
    "                'mask': self.mask,\n",
    "        }\n",
    "        torch.save(d, path)\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, netType, path, device, dir):\n",
    "        loader = torch.load(path)\n",
    "        net_init_state = loader['init_state_dict']\n",
    "        mask = loader['mask']\n",
    "        net = netType\n",
    "        net.load_state_dict(state_dict=loader['model_state_dict'])\n",
    "        net = net.to(device)\n",
    "\n",
    "        wrapper = cls(net, device, dir)\n",
    "        wrapper.net_init_state = net_init_state\n",
    "        wrapper.mask = mask\n",
    "\n",
    "        return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, epochs, model, optimizer, scheduler, criterion, device):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    train_loss = []\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        train_loss_epoch = []\n",
    "        correct_epoch, total_epoch = 0, 0\n",
    "        for ix, (data, _) in enumerate(dataloader):\n",
    "            if ix % 10 == 0:\n",
    "                gc.collect()\n",
    "            inputs, labels = data['X'].to(device), data['cell_type'].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_epoch += labels.size(0)\n",
    "            correct_epoch += (predicted == labels).sum().item()\n",
    "            train_loss.append(loss.item())\n",
    "            train_loss_epoch.append(loss.item())\n",
    "        total += total_epoch\n",
    "        correct += correct_epoch\n",
    "        pbar.set_description(f\"acc: {100 * correct_epoch / total_epoch}, loss: {np.mean(train_loss_epoch)}\")\n",
    "        scheduler.step()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"TRAIN / Total accuracy: {acc}, Total loss: {np.mean(train_loss)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def test(dataloader, model, criterion, device, ds='val'):\n",
    "    assert ds in ['val', 'test']\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for ix, (data, _) in enumerate(dataloader):\n",
    "            inputs, labels = data['X'].to(device), data['cell_type'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"{'VAL ' if ds == 'val' else 'TEST'}  / Total accuracy: {acc}, Total loss: {np.mean(test_loss)}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    return round(acc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = os.path.join(save_path, \"saves\")\n",
    "checkdir(model_save_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215bab1e",
   "metadata": {},
   "source": [
    "For resumability, I added a function to get latest model run\n",
    "\n",
    "The model is only saved after each pruning iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_path, latest_iter = get_latest_run(model_save_dir)\n",
    "if(latest_path is None):\n",
    "    model = PruningWrapper(MLP(input_dim=19331, output_dim=164), device, model_save_dir)\n",
    "else:\n",
    "    model = PruningWrapper.load_model(MLP(input_dim=19331, output_dim=164), latest_path, device, model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATION = 10\n",
    "pruning_amounts = [round(0.1 * (i), 3) for i in range(ITERATION + 1)]\n",
    "\n",
    "epochs_per_iter = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if(latest_iter is None):\n",
    "    start_iter = 0\n",
    "else:\n",
    "    start_iter = latest_iter + 1\n",
    "\n",
    "val_acc = get_latest_valacc(model_save_dir, ds='val')\n",
    "test_acc = get_latest_valacc(model_save_dir, ds='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for ix in range(start_iter, ITERATION):\n",
    "    print(f\"Pruning iter {ix}\")\n",
    "    model.print_model_info()\n",
    "    model.load_init_weights()\n",
    "    model.apply_mask_before_train()\n",
    "    optimizer = torch.optim.AdamW(model.net.parameters(), lr=0.002, weight_decay=0.05)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    train_loss = train(train_loader, epochs_per_iter, model.net, optimizer, scheduler, criterion, device)\n",
    "    val_acc.append(test(val_loader, model.net, criterion, device, ds='val'))\n",
    "    test_acc.append(test(test_loader, model.net, criterion, device, ds='test'))\n",
    "\n",
    "    amt = pruning_amounts[ix + 1]\n",
    "    model.update_mask_after_train(amt)\n",
    "\n",
    "    save_files(ix, model)\n",
    "    save_val_acc(pruning_amounts[:len(val_acc)], val_acc, model_save_dir, ds='val')\n",
    "    save_val_acc(pruning_amounts[:len(test_acc)], test_acc, model_save_dir, ds='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de962ec2",
   "metadata": {},
   "source": [
    "To start from scratch, delete the saves folder and rerun the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6fce92",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Get all predictions of model by iterating over dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    model.net.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    final_labels = torch.Tensor().to(device)\n",
    "    final_preds = torch.Tensor().to(device)\n",
    "    tissues = torch.Tensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ix, (data, _) in enumerate(dataloader):\n",
    "            inputs, labels = data['X'].to(device), data['cell_type'].to(device)\n",
    "            tissue = data['tissue'].to(device)\n",
    "            \n",
    "            outputs = model.net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            final_labels = torch.cat((final_labels, labels))\n",
    "            final_preds = torch.cat((final_preds, predicted))\n",
    "            tissues = torch.cat((tissues, tissue))\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    d = {'labels':final_labels, 'preds':final_preds, 'tissue':tissues}\n",
    "    return d\n",
    "\n",
    "def correct_labels(y_true: np.ndarray, y_pred: np.ndarray, child_matrix: np.ndarray):\n",
    "    \"\"\"\n",
    "    Update predictions.\n",
    "    If prediction is actually a child node of the true label -> update prediction to true value.\n",
    "\n",
    "    E.g: Label='T cell' and prediction='CD8 positive T cell' -> update prediction to 'T cell'\n",
    "    \"\"\"\n",
    "    updated_predictions = y_pred.copy()\n",
    "    # precalculate child nodes\n",
    "    child_nodes = {i: np.where(child_matrix[i, :])[0] for i in range(child_matrix.shape[0])}\n",
    "\n",
    "    for i, (pred, true_label) in enumerate(zip(y_pred, y_true)):\n",
    "        if pred in child_nodes[true_label]:\n",
    "            updated_predictions[i] = true_label\n",
    "        else:\n",
    "            updated_predictions[i] = pred\n",
    "\n",
    "    return updated_predictions\n",
    "\n",
    "def get_f1_score(path, cell_type_hierarchy):\n",
    "\n",
    "    data = torch.load(path)\n",
    "    y_true, y_preds = data['labels'].cpu().numpy(), data['preds'].cpu().numpy()\n",
    "\n",
    "    y_preds_corr = correct_labels(y_true, y_preds, cell_type_hierarchy)\n",
    "\n",
    "    clf_report = pd.DataFrame(classification_report(y_true, y_preds_corr, output_dict=True)).T\n",
    "    clf_report_overall = clf_report.iloc[-3:].copy()\n",
    "    clf_report_per_class = clf_report.iloc[:-3].copy()\n",
    "\n",
    "    return clf_report_overall, clf_report_per_class\n",
    "\n",
    "def save_scores(name, versions, input_dirname, output_dirname, cell_type_hierarchy):\n",
    "    if(name == \"val\"):\n",
    "        f = \"val_preds\"\n",
    "    elif(name == \"test\"):\n",
    "        f = \"test_preds\"\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    for i in versions:\n",
    "        file_path = os.path.join(input_dirname, f\"{f}_{i}\")\n",
    "        print(file_path)\n",
    "        f1_overall, f1_per_class = get_f1_score(file_path, cell_type_hierarchy)\n",
    "        output_fname_overall = os.path.join(output_dirname, f\"f1_overall_{i}.csv\")\n",
    "        output_fname_perclass = os.path.join(output_dirname, f\"f1_perclass_{i}.csv\")\n",
    "        f1_overall.to_csv(output_fname_overall)\n",
    "        f1_per_class.to_csv(output_fname_perclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc153a80",
   "metadata": {},
   "source": [
    "### Saving Predictions for Val and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e480443",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(model_save_dir)\n",
    "model_iters = sorted([int(re.search(r'model_(\\d+)', file).group(1)) for file in files if re.match(r'model_(\\d+)', file)])\n",
    "\n",
    "preds_save_dir = os.path.join(save_path, \"preds\")\n",
    "checkdir(preds_save_dir)\n",
    "\n",
    "for i in model_iters:\n",
    "    model_path = os.path.join(model_save_dir, f\"model_{i}\")\n",
    "    model = PruningWrapper.load_model(MLP(input_dim=19331, output_dim=164), model_path, device, model_save_dir)\n",
    "\n",
    "    valpred_path = os.path.join(preds_save_dir, f\"val_preds_{i}\")\n",
    "    testpred_path = os.path.join(preds_save_dir, f\"test_preds_{i}\")\n",
    "    val_pred_dict = get_preds(model, val_loader, device)\n",
    "    test_pred_dict = get_preds(model, test_loader, device)\n",
    "\n",
    "    torch.save(val_pred_dict, valpred_path)\n",
    "    torch.save(test_pred_dict, testpred_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae47a609",
   "metadata": {},
   "source": [
    "### Creating and Saving F1-Score (overall and per cell type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0dcbea",
   "metadata": {},
   "source": [
    "Initialising directory and reading cell_type_hierarchy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b97995",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_save_dir = os.path.join(save_path, \"f1_scores\")\n",
    "checkdir(scores_save_dir)\n",
    "\n",
    "cell_type_hierarchy = np.load(join(DATA_PATH, 'cell_type_hierarchy/child_matrix.npy'))\n",
    "files = os.listdir(preds_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda1a47",
   "metadata": {},
   "source": [
    "Saving F1-scores for Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_iters = sorted([int(re.search(r'val_preds_(\\d+)', file).group(1)) for file in files if re.match(r'val_preds_(\\d+)', file)])\n",
    "\n",
    "val_scores_save_dir = os.path.join(scores_save_dir, \"val\")\n",
    "checkdir(val_scores_save_dir)\n",
    "\n",
    "save_scores(\"val\", val_pred_iters, preds_save_dir, val_scores_save_dir, cell_type_hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b83cf",
   "metadata": {},
   "source": [
    "Saving F1-scores for Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_iters = sorted([int(re.search(r'test_preds_(\\d+)', file).group(1)) for file in files if re.match(r'test_preds_(\\d+)', file)])\n",
    "\n",
    "test_scores_save_dir = os.path.join(scores_save_dir, \"test\")\n",
    "checkdir(test_scores_save_dir)\n",
    "\n",
    "save_scores(\"test\", val_pred_iters, preds_save_dir, test_scores_save_dir, cell_type_hierarchy)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
